{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('./input/train.csv')\n",
    "X_test = pd.read_csv('./input/test.csv')\n",
    "data = data_train.append(X_test, ignore_index=True, sort=False)\n",
    "data = pd.get_dummies(data, dummy_na=True, drop_first=True)\n",
    "data.drop('Id', axis=1, inplace=True)\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fillna(data.median(), inplace=True)\n",
    "columns = data.columns\n",
    "sale_price = data['SalePrice']\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleType_nan</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SaleCondition_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.125089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.173281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.10125</td>\n",
       "      <td>0.086109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.133562</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.215753</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.116052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    0.235294     0.150685  0.033420     0.666667        0.500   0.949275   \n",
       "1    0.000000     0.202055  0.038795     0.555556        0.875   0.753623   \n",
       "2    0.235294     0.160959  0.046507     0.666667        0.500   0.934783   \n",
       "3    0.294118     0.133562  0.038561     0.666667        0.500   0.311594   \n",
       "4    0.235294     0.215753  0.060576     0.777778        0.500   0.927536   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_New  \\\n",
       "0      0.883333     0.12250    0.125089         0.0  ...           0.0   \n",
       "1      0.433333     0.00000    0.173281         0.0  ...           0.0   \n",
       "2      0.866667     0.10125    0.086109         0.0  ...           0.0   \n",
       "3      0.333333     0.00000    0.038271         0.0  ...           0.0   \n",
       "4      0.833333     0.21875    0.116052         0.0  ...           0.0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleType_nan  SaleCondition_AdjLand  \\\n",
       "0           0.0          1.0           0.0                    0.0   \n",
       "1           0.0          1.0           0.0                    0.0   \n",
       "2           0.0          1.0           0.0                    0.0   \n",
       "3           0.0          1.0           0.0                    0.0   \n",
       "4           0.0          1.0           0.0                    0.0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                   0.0                   0.0                   1.0   \n",
       "1                   0.0                   0.0                   1.0   \n",
       "2                   0.0                   0.0                   1.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   1.0   \n",
       "\n",
       "   SaleCondition_Partial  SaleCondition_nan  \n",
       "0                    0.0                0.0  \n",
       "1                    0.0                0.0  \n",
       "2                    0.0                0.0  \n",
       "3                    0.0                0.0  \n",
       "4                    0.0                0.0  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns = columns)\n",
    "data['SalePrice'] = sale_price\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\cuda\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train = data.iloc[:1460]\n",
    "test = data.iloc[1460:]\n",
    "test.drop('SalePrice', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.drop('SalePrice', axis=1), train['SalePrice'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 288)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(144, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(72, activation='relu'))\n",
    "    model.add(layers.Dense(18, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 144)               41616     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 72)                10440     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                1314      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 53,389\n",
      "Trainable params: 53,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "num_epochs = 300\n",
    "k = 4\n",
    "num_val_samples = len(X_train) // k\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/300\n",
      "1168/1168 [==============================] - 2s 2ms/step - loss: 38876751132.0548 - mean_absolute_error: 181417.5493 - val_loss: 39625154349.5890 - val_mean_absolute_error: 178760.3579\n",
      "Epoch 2/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 38817239646.6849 - mean_absolute_error: 181256.2393 - val_loss: 39527785205.4795 - val_mean_absolute_error: 178491.1428\n",
      "Epoch 3/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 38672543887.7808 - mean_absolute_error: 180863.9060 - val_loss: 39327663749.2603 - val_mean_absolute_error: 177936.5156\n",
      "Epoch 4/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 38410747942.5753 - mean_absolute_error: 180139.0780 - val_loss: 38994037142.7945 - val_mean_absolute_error: 177007.4667\n",
      "Epoch 5/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 37989170502.1370 - mean_absolute_error: 178978.9127 - val_loss: 38481062799.7808 - val_mean_absolute_error: 175569.3354\n",
      "Epoch 6/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 37368973006.9041 - mean_absolute_error: 177254.9169 - val_loss: 37750276727.2329 - val_mean_absolute_error: 173500.5829\n",
      "Epoch 7/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 36503223741.3699 - mean_absolute_error: 174838.9410 - val_loss: 36762253831.0137 - val_mean_absolute_error: 170663.4587\n",
      "Epoch 8/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 35371512421.6986 - mean_absolute_error: 171583.6944 - val_loss: 35472061790.6849 - val_mean_absolute_error: 166888.0973\n",
      "Epoch 9/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 33918261153.3151 - mean_absolute_error: 167336.5912 - val_loss: 33882653022.6849 - val_mean_absolute_error: 162114.7921\n",
      "Epoch 10/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 32129303678.2466 - mean_absolute_error: 161973.3651 - val_loss: 31930473331.7260 - val_mean_absolute_error: 156056.6010\n",
      "Epoch 11/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 29995939724.2740 - mean_absolute_error: 155271.5337 - val_loss: 29650566144.0000 - val_mean_absolute_error: 148670.3676\n",
      "Epoch 12/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 27514388465.9726 - mean_absolute_error: 147129.1458 - val_loss: 27041539576.9863 - val_mean_absolute_error: 139744.3494\n",
      "Epoch 13/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 24698427602.4110 - mean_absolute_error: 137410.9196 - val_loss: 24113719576.5479 - val_mean_absolute_error: 129066.4321\n",
      "Epoch 14/300\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 21613951616.0000 - mean_absolute_error: 125860.6930 - val_loss: 21007564898.1918 - val_mean_absolute_error: 116752.1923\n",
      "Epoch 15/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 18386315991.6712 - mean_absolute_error: 112534.1889 - val_loss: 17790050584.5479 - val_mean_absolute_error: 102644.5570\n",
      "Epoch 16/300\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 15114442766.9041 - mean_absolute_error: 97524.3849 - val_loss: 14613357511.8904 - val_mean_absolute_error: 87383.7428\n",
      "Epoch 17/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 11945385233.5342 - mean_absolute_error: 81412.2164 - val_loss: 11696997025.3151 - val_mean_absolute_error: 71626.3024\n",
      "Epoch 18/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 9219547364.8219 - mean_absolute_error: 65952.4417 - val_loss: 9352037702.1370 - val_mean_absolute_error: 59482.9922\n",
      "Epoch 19/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 7086795483.6164 - mean_absolute_error: 54399.7169 - val_loss: 7736531922.4110 - val_mean_absolute_error: 53951.9314\n",
      "Epoch 20/300\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 5771817679.3425 - mean_absolute_error: 49807.3302 - val_loss: 6855565131.3973 - val_mean_absolute_error: 54063.0092\n",
      "Epoch 21/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 5139760454.7945 - mean_absolute_error: 49318.5739 - val_loss: 6518267258.7397 - val_mean_absolute_error: 55337.4203\n",
      "Epoch 22/300\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 4910352038.7945 - mean_absolute_error: 49626.6140 - val_loss: 6324903115.3973 - val_mean_absolute_error: 54545.7808\n",
      "Epoch 23/300\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 4748639080.3288 - mean_absolute_error: 48784.9934 - val_loss: 6131993305.4247 - val_mean_absolute_error: 54107.4961\n",
      "Epoch 24/300\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 4574727363.7260 - mean_absolute_error: 47315.1702 - val_loss: 5979270643.7260 - val_mean_absolute_error: 54968.5202\n",
      "Epoch 25/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 4438630650.3014 - mean_absolute_error: 47523.0342 - val_loss: 5772461496.1096 - val_mean_absolute_error: 52218.7856\n",
      "Epoch 26/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 4292312295.6712 - mean_absolute_error: 46255.4215 - val_loss: 5600168470.7945 - val_mean_absolute_error: 50673.4378\n",
      "Epoch 27/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 4147737847.6712 - mean_absolute_error: 44879.0985 - val_loss: 5433067718.1370 - val_mean_absolute_error: 50063.6440\n",
      "Epoch 28/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 4013409859.5068 - mean_absolute_error: 44213.0525 - val_loss: 5264458434.6301 - val_mean_absolute_error: 48576.1328\n",
      "Epoch 29/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 3874775204.3836 - mean_absolute_error: 42891.8961 - val_loss: 5118004458.9589 - val_mean_absolute_error: 49291.5747\n",
      "Epoch 30/300\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 3747170875.1781 - mean_absolute_error: 42557.0197 - val_loss: 4951841325.5890 - val_mean_absolute_error: 47448.5414\n",
      "Epoch 31/300\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 3619349831.2329 - mean_absolute_error: 41626.6835 - val_loss: 4794774400.0000 - val_mean_absolute_error: 45959.9067\n",
      "Epoch 32/300\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 3504954586.9589 - mean_absolute_error: 40180.0133 - val_loss: 4651874766.9041 - val_mean_absolute_error: 45180.1484\n",
      "Epoch 33/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 3388877558.5753 - mean_absolute_error: 39651.9729 - val_loss: 4511548959.5616 - val_mean_absolute_error: 44030.5450\n",
      "Epoch 34/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 3271642371.2877 - mean_absolute_error: 38702.1271 - val_loss: 4367144269.1507 - val_mean_absolute_error: 42318.7482\n",
      "Epoch 35/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 3163432321.9726 - mean_absolute_error: 37872.8980 - val_loss: 4236347895.2329 - val_mean_absolute_error: 41713.5868\n",
      "Epoch 36/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 3061616821.2603 - mean_absolute_error: 37002.7843 - val_loss: 4109138013.8082 - val_mean_absolute_error: 40466.9838\n",
      "Epoch 37/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 2962504370.6301 - mean_absolute_error: 36295.6075 - val_loss: 3985648543.5616 - val_mean_absolute_error: 39744.9241\n",
      "Epoch 38/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 2868203082.8493 - mean_absolute_error: 35455.7531 - val_loss: 3862133610.9589 - val_mean_absolute_error: 38585.4600\n",
      "Epoch 39/300\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 2769737966.0274 - mean_absolute_error: 34906.9758 - val_loss: 3737410589.8082 - val_mean_absolute_error: 37483.7326\n",
      "Epoch 40/300\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 2679641852.0548 - mean_absolute_error: 33824.7569 - val_loss: 3629328706.6301 - val_mean_absolute_error: 36577.5434\n",
      "Epoch 41/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 2594192625.9726 - mean_absolute_error: 33160.9207 - val_loss: 3521815004.0548 - val_mean_absolute_error: 35529.7737\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 88us/step - loss: 2519709154.8493 - mean_absolute_error: 32508.5296 - val_loss: 3425902538.5205 - val_mean_absolute_error: 34776.9237\n",
      "Epoch 43/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 2443632977.9726 - mean_absolute_error: 31914.8322 - val_loss: 3340391357.3699 - val_mean_absolute_error: 33619.6948\n",
      "Epoch 44/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 2379083046.9041 - mean_absolute_error: 31128.4291 - val_loss: 3248900378.3014 - val_mean_absolute_error: 33250.9011\n",
      "Epoch 45/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 2317050317.3699 - mean_absolute_error: 30659.0607 - val_loss: 3162101557.4795 - val_mean_absolute_error: 33008.4680\n",
      "Epoch 46/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 2255839867.2877 - mean_absolute_error: 29965.9844 - val_loss: 3093208816.2192 - val_mean_absolute_error: 33993.7192\n",
      "Epoch 47/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 2202525349.6986 - mean_absolute_error: 30341.0476 - val_loss: 3035402979.9452 - val_mean_absolute_error: 31361.7804\n",
      "Epoch 48/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 2162320359.6712 - mean_absolute_error: 29193.5797 - val_loss: 2962627402.5205 - val_mean_absolute_error: 31589.7335\n",
      "Epoch 49/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 2110055652.8219 - mean_absolute_error: 29076.6409 - val_loss: 2893219313.0959 - val_mean_absolute_error: 31349.7140\n",
      "Epoch 50/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 2057105762.1918 - mean_absolute_error: 28953.1283 - val_loss: 2843734873.8630 - val_mean_absolute_error: 30576.2058\n",
      "Epoch 51/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 2022272702.6849 - mean_absolute_error: 28407.7420 - val_loss: 2784901476.8219 - val_mean_absolute_error: 30698.4599\n",
      "Epoch 52/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 1976511238.1370 - mean_absolute_error: 28213.4210 - val_loss: 2732615583.1233 - val_mean_absolute_error: 30459.0956\n",
      "Epoch 53/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1941066510.2466 - mean_absolute_error: 28015.2335 - val_loss: 2692031807.5616 - val_mean_absolute_error: 29987.1550\n",
      "Epoch 54/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 1907291329.2055 - mean_absolute_error: 27673.1820 - val_loss: 2641713521.0959 - val_mean_absolute_error: 30164.9433\n",
      "Epoch 55/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 1875436208.3288 - mean_absolute_error: 27519.3352 - val_loss: 2609281070.4658 - val_mean_absolute_error: 29478.6003\n",
      "Epoch 56/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 1841079728.3288 - mean_absolute_error: 27067.4729 - val_loss: 2560787257.4247 - val_mean_absolute_error: 30019.0273\n",
      "Epoch 57/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1811165186.6301 - mean_absolute_error: 26982.2136 - val_loss: 2523307424.4384 - val_mean_absolute_error: 30122.1283\n",
      "Epoch 58/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1778319820.6027 - mean_absolute_error: 26877.2659 - val_loss: 2487588205.5890 - val_mean_absolute_error: 29878.2055\n",
      "Epoch 59/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 1749348343.1233 - mean_absolute_error: 26598.0727 - val_loss: 2447213027.9452 - val_mean_absolute_error: 29320.7966\n",
      "Epoch 60/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1723449160.5479 - mean_absolute_error: 26376.9986 - val_loss: 2415942315.8356 - val_mean_absolute_error: 28940.1201\n",
      "Epoch 61/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 1693393852.7671 - mean_absolute_error: 26121.7859 - val_loss: 2388575042.6301 - val_mean_absolute_error: 28482.8170\n",
      "Epoch 62/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1666392361.1507 - mean_absolute_error: 25766.4893 - val_loss: 2350536036.3836 - val_mean_absolute_error: 28966.8257\n",
      "Epoch 63/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 1640804995.9452 - mean_absolute_error: 25995.7330 - val_loss: 2333129444.8219 - val_mean_absolute_error: 28038.4412\n",
      "Epoch 64/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 1615553645.0411 - mean_absolute_error: 25449.3104 - val_loss: 2301482083.0685 - val_mean_absolute_error: 27882.2953\n",
      "Epoch 65/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1594042695.1233 - mean_absolute_error: 25232.7168 - val_loss: 2262119060.6027 - val_mean_absolute_error: 27983.4870\n",
      "Epoch 66/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 1565301692.9315 - mean_absolute_error: 25256.2236 - val_loss: 2246718522.3014 - val_mean_absolute_error: 27564.9237\n",
      "Epoch 67/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1552074259.5068 - mean_absolute_error: 24851.9119 - val_loss: 2213002688.4384 - val_mean_absolute_error: 27564.0991\n",
      "Epoch 68/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 1528162522.6301 - mean_absolute_error: 24724.8583 - val_loss: 2186543111.8904 - val_mean_absolute_error: 27425.1800\n",
      "Epoch 69/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1507099246.1370 - mean_absolute_error: 24536.3680 - val_loss: 2153409912.9863 - val_mean_absolute_error: 27567.5612\n",
      "Epoch 70/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 1486503426.8493 - mean_absolute_error: 24398.3939 - val_loss: 2125773903.7808 - val_mean_absolute_error: 27442.1777\n",
      "Epoch 71/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 1467202266.6301 - mean_absolute_error: 24270.0842 - val_loss: 2109130532.8219 - val_mean_absolute_error: 27007.7101\n",
      "Epoch 72/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 1447869388.3288 - mean_absolute_error: 23995.5631 - val_loss: 2080831456.0000 - val_mean_absolute_error: 27267.8289\n",
      "Epoch 73/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 1431537020.6575 - mean_absolute_error: 24036.0089 - val_loss: 2054030016.4384 - val_mean_absolute_error: 27155.8513\n",
      "Epoch 74/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 1410915889.9726 - mean_absolute_error: 23871.0148 - val_loss: 2033137324.2740 - val_mean_absolute_error: 26754.0003\n",
      "Epoch 75/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1390932182.3562 - mean_absolute_error: 23791.1178 - val_loss: 2015503182.0274 - val_mean_absolute_error: 26518.2756\n",
      "Epoch 76/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1376009871.8356 - mean_absolute_error: 23474.5777 - val_loss: 1989675946.5205 - val_mean_absolute_error: 26561.3553\n",
      "Epoch 77/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1364651041.3151 - mean_absolute_error: 23428.0982 - val_loss: 1978992705.3151 - val_mean_absolute_error: 26185.6178\n",
      "Epoch 78/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1345601748.4932 - mean_absolute_error: 23254.2558 - val_loss: 1969380704.8767 - val_mean_absolute_error: 25984.5535\n",
      "Epoch 79/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1335568664.0548 - mean_absolute_error: 23087.1383 - val_loss: 1943925384.7671 - val_mean_absolute_error: 25916.9352\n",
      "Epoch 80/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1320183239.7260 - mean_absolute_error: 22873.5487 - val_loss: 1915058393.8630 - val_mean_absolute_error: 26196.2073\n",
      "Epoch 81/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1303907116.4384 - mean_absolute_error: 22908.5629 - val_loss: 1911756568.1096 - val_mean_absolute_error: 25636.7390\n",
      "Epoch 82/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 1293101425.5342 - mean_absolute_error: 22699.9765 - val_loss: 1878120504.5479 - val_mean_absolute_error: 25717.2737\n",
      "Epoch 83/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1273920567.4521 - mean_absolute_error: 22601.0979 - val_loss: 1855710026.0822 - val_mean_absolute_error: 25835.6029\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 93us/step - loss: 1265717574.1370 - mean_absolute_error: 22586.3292 - val_loss: 1837548706.6301 - val_mean_absolute_error: 25762.0768\n",
      "Epoch 85/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 1255581093.5342 - mean_absolute_error: 22552.5890 - val_loss: 1823564130.6301 - val_mean_absolute_error: 25369.6851\n",
      "Epoch 86/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 1240711483.8356 - mean_absolute_error: 22313.0418 - val_loss: 1805500136.7671 - val_mean_absolute_error: 25304.0294\n",
      "Epoch 87/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 1231210122.2466 - mean_absolute_error: 22166.2130 - val_loss: 1791532460.7123 - val_mean_absolute_error: 25198.0470\n",
      "Epoch 88/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 1220034859.2329 - mean_absolute_error: 22053.4552 - val_loss: 1775287886.4658 - val_mean_absolute_error: 25460.8191\n",
      "Epoch 89/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 1210166513.9726 - mean_absolute_error: 22147.5468 - val_loss: 1784997258.0822 - val_mean_absolute_error: 24830.2769\n",
      "Epoch 90/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1205032719.6164 - mean_absolute_error: 21834.7212 - val_loss: 1751745085.8082 - val_mean_absolute_error: 24848.2520\n",
      "Epoch 91/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 1192465483.7260 - mean_absolute_error: 21809.0219 - val_loss: 1736946846.6849 - val_mean_absolute_error: 24795.4012\n",
      "Epoch 92/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 1183865329.4247 - mean_absolute_error: 21592.7500 - val_loss: 1720354515.7260 - val_mean_absolute_error: 24971.9796\n",
      "Epoch 93/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 1175728154.4658 - mean_absolute_error: 21819.9619 - val_loss: 1725633472.8767 - val_mean_absolute_error: 24540.6010\n",
      "Epoch 94/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 1149433657.3151 - mean_absolute_error: 21465.5034 - val_loss: 1697784209.5342 - val_mean_absolute_error: 25206.0046\n",
      "Epoch 95/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 1158631500.1096 - mean_absolute_error: 21617.9130 - val_loss: 1687612814.9041 - val_mean_absolute_error: 24443.0075\n",
      "Epoch 96/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1146599185.9178 - mean_absolute_error: 21407.2599 - val_loss: 1670380353.3151 - val_mean_absolute_error: 24423.5585\n",
      "Epoch 97/300\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 1138822627.5616 - mean_absolute_error: 21320.6948 - val_loss: 1657784666.7397 - val_mean_absolute_error: 24348.2945\n",
      "Epoch 98/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 1127515791.7808 - mean_absolute_error: 21284.0664 - val_loss: 1652641304.1096 - val_mean_absolute_error: 24217.8470\n",
      "Epoch 99/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 1121827582.4658 - mean_absolute_error: 21059.2234 - val_loss: 1637296869.6986 - val_mean_absolute_error: 24180.7336\n",
      "Epoch 100/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 1116979559.7260 - mean_absolute_error: 20984.1943 - val_loss: 1625533963.3973 - val_mean_absolute_error: 24159.6501\n",
      "Epoch 101/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 1107857442.7945 - mean_absolute_error: 20926.1064 - val_loss: 1614647114.5205 - val_mean_absolute_error: 24365.3945\n",
      "Epoch 102/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 1101912136.0000 - mean_absolute_error: 20900.5728 - val_loss: 1613928590.6849 - val_mean_absolute_error: 23962.5270\n",
      "Epoch 103/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 1096687290.7945 - mean_absolute_error: 20801.5654 - val_loss: 1597642053.9178 - val_mean_absolute_error: 23917.6956\n",
      "Epoch 104/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 1086589944.8767 - mean_absolute_error: 20687.2352 - val_loss: 1582615186.1918 - val_mean_absolute_error: 23998.1997\n",
      "Epoch 105/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1076266721.9178 - mean_absolute_error: 20566.1716 - val_loss: 1578856467.7260 - val_mean_absolute_error: 24332.4980\n",
      "Epoch 106/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 1071343583.7260 - mean_absolute_error: 20541.5388 - val_loss: 1566697941.0411 - val_mean_absolute_error: 24071.0726\n",
      "Epoch 107/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 1066806563.4521 - mean_absolute_error: 20542.6741 - val_loss: 1582285205.2603 - val_mean_absolute_error: 23728.2189\n",
      "Epoch 108/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 1062589685.6986 - mean_absolute_error: 20404.4432 - val_loss: 1544348477.5890 - val_mean_absolute_error: 23692.3118\n",
      "Epoch 109/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 1053942814.4658 - mean_absolute_error: 20351.8088 - val_loss: 1550338970.5205 - val_mean_absolute_error: 23536.4680\n",
      "Epoch 110/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 1047955540.0000 - mean_absolute_error: 20276.7018 - val_loss: 1532415177.8630 - val_mean_absolute_error: 23453.6713\n",
      "Epoch 111/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 1041646934.5205 - mean_absolute_error: 20213.7509 - val_loss: 1537536002.8493 - val_mean_absolute_error: 23447.1337\n",
      "Epoch 112/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 1039484508.9315 - mean_absolute_error: 20138.1809 - val_loss: 1510071551.3425 - val_mean_absolute_error: 23401.7752\n",
      "Epoch 113/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 1029105949.5890 - mean_absolute_error: 20060.4514 - val_loss: 1503573231.5616 - val_mean_absolute_error: 23318.8484\n",
      "Epoch 114/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 1024958330.3562 - mean_absolute_error: 19965.2000 - val_loss: 1496314005.4795 - val_mean_absolute_error: 23243.7526\n",
      "Epoch 115/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 1017224179.2877 - mean_absolute_error: 19963.2087 - val_loss: 1493029770.0822 - val_mean_absolute_error: 23189.3675\n",
      "Epoch 116/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 1010750923.3425 - mean_absolute_error: 19797.3365 - val_loss: 1487508889.6438 - val_mean_absolute_error: 23100.6473\n",
      "Epoch 117/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 1010405526.7397 - mean_absolute_error: 19646.9157 - val_loss: 1470212585.8630 - val_mean_absolute_error: 23080.8955\n",
      "Epoch 118/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 1001853224.8767 - mean_absolute_error: 19651.1005 - val_loss: 1467059946.9589 - val_mean_absolute_error: 23020.8538\n",
      "Epoch 119/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 994666929.4247 - mean_absolute_error: 19621.5062 - val_loss: 1458580679.2329 - val_mean_absolute_error: 22969.0135\n",
      "Epoch 120/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 992081242.5205 - mean_absolute_error: 19578.4947 - val_loss: 1443284091.6164 - val_mean_absolute_error: 22953.2600\n",
      "Epoch 121/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 985337261.8082 - mean_absolute_error: 19508.9072 - val_loss: 1436123214.4658 - val_mean_absolute_error: 22959.0807\n",
      "Epoch 122/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 982537827.2877 - mean_absolute_error: 19442.2809 - val_loss: 1435721663.5616 - val_mean_absolute_error: 22828.2391\n",
      "Epoch 123/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 976503249.3699 - mean_absolute_error: 19361.8687 - val_loss: 1425128309.0411 - val_mean_absolute_error: 22760.7623\n",
      "Epoch 124/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 971533439.6164 - mean_absolute_error: 19251.8976 - val_loss: 1415710596.6027 - val_mean_absolute_error: 22675.2453\n",
      "Epoch 125/300\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 966450796.0000 - mean_absolute_error: 19253.9967 - val_loss: 1407965909.2603 - val_mean_absolute_error: 22612.2231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/300\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 961097376.0000 - mean_absolute_error: 19143.6387 - val_loss: 1404827125.9178 - val_mean_absolute_error: 22587.5902\n",
      "Epoch 127/300\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 955297034.3014 - mean_absolute_error: 19075.3393 - val_loss: 1394924011.8356 - val_mean_absolute_error: 22486.4444\n",
      "Epoch 128/300\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 953275099.9452 - mean_absolute_error: 19071.5711 - val_loss: 1393807886.9041 - val_mean_absolute_error: 22491.0821\n",
      "Epoch 129/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 943865116.6575 - mean_absolute_error: 18903.1237 - val_loss: 1382495019.6164 - val_mean_absolute_error: 22587.6949\n",
      "Epoch 130/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 943773504.8219 - mean_absolute_error: 18958.7492 - val_loss: 1371877553.7534 - val_mean_absolute_error: 22403.1357\n",
      "Epoch 131/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 935184596.5479 - mean_absolute_error: 18927.5760 - val_loss: 1372305651.2877 - val_mean_absolute_error: 22332.1989\n",
      "Epoch 132/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 932405299.6164 - mean_absolute_error: 18802.3981 - val_loss: 1366783903.5616 - val_mean_absolute_error: 22253.5135\n",
      "Epoch 133/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 930767079.3425 - mean_absolute_error: 18855.3495 - val_loss: 1360059307.8356 - val_mean_absolute_error: 22205.2119\n",
      "Epoch 134/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 921553703.0137 - mean_absolute_error: 18726.1444 - val_loss: 1347354129.7534 - val_mean_absolute_error: 22169.8920\n",
      "Epoch 135/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 915159793.2603 - mean_absolute_error: 18750.0103 - val_loss: 1365076747.6164 - val_mean_absolute_error: 22306.5917\n",
      "Epoch 136/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 911867184.5205 - mean_absolute_error: 18534.0978 - val_loss: 1381562344.9863 - val_mean_absolute_error: 22470.0020\n",
      "Epoch 137/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 914506488.0548 - mean_absolute_error: 18533.7625 - val_loss: 1331414831.3425 - val_mean_absolute_error: 22014.0853\n",
      "Epoch 138/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 905685859.1233 - mean_absolute_error: 18471.8417 - val_loss: 1330380460.7123 - val_mean_absolute_error: 21991.5658\n",
      "Epoch 139/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 905465317.1507 - mean_absolute_error: 18491.0332 - val_loss: 1319537950.0274 - val_mean_absolute_error: 21918.8002\n",
      "Epoch 140/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 898653407.6164 - mean_absolute_error: 18353.4163 - val_loss: 1312779884.9315 - val_mean_absolute_error: 21889.4363\n",
      "Epoch 141/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 898317245.2055 - mean_absolute_error: 18374.5940 - val_loss: 1341935375.3425 - val_mean_absolute_error: 22175.6565\n",
      "Epoch 142/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 893652273.8082 - mean_absolute_error: 18355.0992 - val_loss: 1322233959.6712 - val_mean_absolute_error: 21899.0379\n",
      "Epoch 143/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 885348282.5753 - mean_absolute_error: 18148.4728 - val_loss: 1303393773.8082 - val_mean_absolute_error: 21747.7377\n",
      "Epoch 144/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 888191814.9041 - mean_absolute_error: 18175.9912 - val_loss: 1302978676.6027 - val_mean_absolute_error: 21753.3602\n",
      "Epoch 145/300\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 886648085.8356 - mean_absolute_error: 18189.2187 - val_loss: 1289599236.6027 - val_mean_absolute_error: 21683.4135\n",
      "Epoch 146/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 880976348.7123 - mean_absolute_error: 18135.8791 - val_loss: 1289523210.0822 - val_mean_absolute_error: 21721.7045\n",
      "Epoch 147/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 875281632.8219 - mean_absolute_error: 18000.1834 - val_loss: 1287167498.3014 - val_mean_absolute_error: 21691.5781\n",
      "Epoch 148/300\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 875308176.6027 - mean_absolute_error: 18018.4353 - val_loss: 1275525891.9452 - val_mean_absolute_error: 21569.1726\n",
      "Epoch 149/300\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 867487971.1233 - mean_absolute_error: 17927.4436 - val_loss: 1270027685.0411 - val_mean_absolute_error: 21566.7878\n",
      "Epoch 150/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 866625314.2466 - mean_absolute_error: 17996.6534 - val_loss: 1269135901.1507 - val_mean_absolute_error: 21593.8452\n",
      "Epoch 151/300\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 863345676.2740 - mean_absolute_error: 17899.6088 - val_loss: 1262157273.2055 - val_mean_absolute_error: 21468.9864\n",
      "Epoch 152/300\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 864687893.3425 - mean_absolute_error: 17839.8094 - val_loss: 1262247550.6849 - val_mean_absolute_error: 21394.8247\n",
      "Epoch 153/300\n",
      "1168/1168 [==============================] - 0s 101us/step - loss: 856703727.6712 - mean_absolute_error: 17826.6696 - val_loss: 1261489451.1781 - val_mean_absolute_error: 21458.3706\n",
      "Epoch 154/300\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 853098761.5342 - mean_absolute_error: 17774.8526 - val_loss: 1259331343.5616 - val_mean_absolute_error: 21412.0828\n",
      "Epoch 155/300\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 852085644.4932 - mean_absolute_error: 17704.2948 - val_loss: 1252624031.7808 - val_mean_absolute_error: 21370.0720\n",
      "Epoch 156/300\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 847615526.1370 - mean_absolute_error: 17684.2243 - val_loss: 1243580018.8493 - val_mean_absolute_error: 21255.6946\n",
      "Epoch 157/300\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 844254062.8493 - mean_absolute_error: 17641.2152 - val_loss: 1239372474.7397 - val_mean_absolute_error: 21253.7817\n",
      "Epoch 158/300\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 842168084.3836 - mean_absolute_error: 17561.6240 - val_loss: 1231031251.2877 - val_mean_absolute_error: 21201.3119\n",
      "Epoch 159/300\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 839853633.6438 - mean_absolute_error: 17599.2826 - val_loss: 1232328396.7123 - val_mean_absolute_error: 21239.6302\n",
      "Epoch 160/300\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 833899503.8082 - mean_absolute_error: 17553.1369 - val_loss: 1229316835.2877 - val_mean_absolute_error: 21203.9749\n",
      "Epoch 161/300\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 834427114.1918 - mean_absolute_error: 17524.8006 - val_loss: 1223923986.8493 - val_mean_absolute_error: 21128.2373\n",
      "Epoch 162/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 832867705.7534 - mean_absolute_error: 17477.4210 - val_loss: 1228121427.5068 - val_mean_absolute_error: 21211.6467\n",
      "Epoch 163/300\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 827605366.9041 - mean_absolute_error: 17418.9884 - val_loss: 1211703425.7534 - val_mean_absolute_error: 21055.2772\n",
      "Epoch 164/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 827098637.2329 - mean_absolute_error: 17476.6734 - val_loss: 1215136693.6986 - val_mean_absolute_error: 21142.3446\n",
      "Epoch 165/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 822760571.4247 - mean_absolute_error: 17348.5241 - val_loss: 1214281028.1644 - val_mean_absolute_error: 21085.9063\n",
      "Epoch 166/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 820005018.1370 - mean_absolute_error: 17324.7879 - val_loss: 1205826654.4658 - val_mean_absolute_error: 21015.4508\n",
      "Epoch 167/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 817958373.6986 - mean_absolute_error: 17258.0007 - val_loss: 1202313667.0685 - val_mean_absolute_error: 20962.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 815658928.6301 - mean_absolute_error: 17297.8180 - val_loss: 1198713001.8630 - val_mean_absolute_error: 20919.0255\n",
      "Epoch 169/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 813032518.7945 - mean_absolute_error: 17208.1134 - val_loss: 1193722582.1370 - val_mean_absolute_error: 20877.3546\n",
      "Epoch 170/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 807108667.3425 - mean_absolute_error: 17159.2809 - val_loss: 1209404454.5753 - val_mean_absolute_error: 21076.4313\n",
      "Epoch 171/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 810102964.5753 - mean_absolute_error: 17149.5575 - val_loss: 1187360140.7123 - val_mean_absolute_error: 20890.8764\n",
      "Epoch 172/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 806208862.4932 - mean_absolute_error: 17087.7153 - val_loss: 1189825519.3425 - val_mean_absolute_error: 20884.9422\n",
      "Epoch 173/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 801997162.0274 - mean_absolute_error: 17045.6039 - val_loss: 1181108619.3973 - val_mean_absolute_error: 20912.7850\n",
      "Epoch 174/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 803254537.2603 - mean_absolute_error: 17096.1426 - val_loss: 1175372580.6027 - val_mean_absolute_error: 20815.6330\n",
      "Epoch 175/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 798068831.1781 - mean_absolute_error: 17048.7835 - val_loss: 1167552857.6438 - val_mean_absolute_error: 20772.5506\n",
      "Epoch 176/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 795790304.7671 - mean_absolute_error: 16996.4037 - val_loss: 1179093329.0959 - val_mean_absolute_error: 20871.4732\n",
      "Epoch 177/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 792753784.1918 - mean_absolute_error: 16963.1288 - val_loss: 1182695960.9863 - val_mean_absolute_error: 20888.5234\n",
      "Epoch 178/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 787840468.1096 - mean_absolute_error: 16905.7426 - val_loss: 1188027775.3425 - val_mean_absolute_error: 21033.3747\n",
      "Epoch 179/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 788710242.5753 - mean_absolute_error: 16878.8151 - val_loss: 1158913167.3425 - val_mean_absolute_error: 20654.9025\n",
      "Epoch 180/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 787000354.3836 - mean_absolute_error: 16872.9029 - val_loss: 1157778778.9589 - val_mean_absolute_error: 20668.1848\n",
      "Epoch 181/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 784428897.6986 - mean_absolute_error: 16852.5592 - val_loss: 1152005188.3836 - val_mean_absolute_error: 20649.9432\n",
      "Epoch 182/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 784499371.2055 - mean_absolute_error: 16826.6112 - val_loss: 1150645447.6712 - val_mean_absolute_error: 20620.1441\n",
      "Epoch 183/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 776859009.0959 - mean_absolute_error: 16834.1797 - val_loss: 1153934091.8356 - val_mean_absolute_error: 20956.5751\n",
      "Epoch 184/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 780035838.3836 - mean_absolute_error: 16896.0399 - val_loss: 1144284982.5753 - val_mean_absolute_error: 20624.5968\n",
      "Epoch 185/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 776296645.2603 - mean_absolute_error: 16694.9095 - val_loss: 1144728084.8219 - val_mean_absolute_error: 20601.9462\n",
      "Epoch 186/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 770322280.5479 - mean_absolute_error: 16726.8064 - val_loss: 1140948097.3151 - val_mean_absolute_error: 20582.6843\n",
      "Epoch 187/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 769415505.8082 - mean_absolute_error: 16685.5786 - val_loss: 1132516626.6301 - val_mean_absolute_error: 20563.8994\n",
      "Epoch 188/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 770245341.9452 - mean_absolute_error: 16660.5329 - val_loss: 1145870036.1644 - val_mean_absolute_error: 20636.0552\n",
      "Epoch 189/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 767528966.7397 - mean_absolute_error: 16641.2258 - val_loss: 1135256800.2192 - val_mean_absolute_error: 20537.7894\n",
      "Epoch 190/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 762897906.6301 - mean_absolute_error: 16561.3004 - val_loss: 1122514478.4658 - val_mean_absolute_error: 20555.6476\n",
      "Epoch 191/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 761844342.3836 - mean_absolute_error: 16576.3245 - val_loss: 1120371962.5205 - val_mean_absolute_error: 20492.6345\n",
      "Epoch 192/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 757363257.6438 - mean_absolute_error: 16615.7206 - val_loss: 1117439121.0959 - val_mean_absolute_error: 20522.8309\n",
      "Epoch 193/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 761208943.2877 - mean_absolute_error: 16537.1039 - val_loss: 1118589706.9589 - val_mean_absolute_error: 20467.6337\n",
      "Epoch 194/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 757867880.2740 - mean_absolute_error: 16593.8418 - val_loss: 1140747309.8082 - val_mean_absolute_error: 20594.8343\n",
      "Epoch 195/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 756978601.8630 - mean_absolute_error: 16464.8441 - val_loss: 1126915461.9178 - val_mean_absolute_error: 20370.6201\n",
      "Epoch 196/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 752863104.7945 - mean_absolute_error: 16445.7710 - val_loss: 1121037886.9041 - val_mean_absolute_error: 20325.2801\n",
      "Epoch 197/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 752150373.1781 - mean_absolute_error: 16433.8930 - val_loss: 1113607346.4110 - val_mean_absolute_error: 20310.4993\n",
      "Epoch 198/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 753356293.2055 - mean_absolute_error: 16396.3443 - val_loss: 1114472301.8082 - val_mean_absolute_error: 20298.7192\n",
      "Epoch 199/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 750158970.7123 - mean_absolute_error: 16365.2303 - val_loss: 1108620391.2329 - val_mean_absolute_error: 20279.7645\n",
      "Epoch 200/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 751163127.7808 - mean_absolute_error: 16350.7534 - val_loss: 1105310400.0000 - val_mean_absolute_error: 20292.0101\n",
      "Epoch 201/300\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 746599941.4795 - mean_absolute_error: 16312.7444 - val_loss: 1107955430.5753 - val_mean_absolute_error: 20272.4607\n",
      "Epoch 202/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 743527902.0548 - mean_absolute_error: 16244.5772 - val_loss: 1111603982.9041 - val_mean_absolute_error: 20282.4976\n",
      "Epoch 203/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 743338554.9589 - mean_absolute_error: 16306.5619 - val_loss: 1100553371.3973 - val_mean_absolute_error: 20250.4897\n",
      "Epoch 204/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 742289197.4795 - mean_absolute_error: 16298.9773 - val_loss: 1098770667.1781 - val_mean_absolute_error: 20244.0945\n",
      "Epoch 205/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 739503690.8219 - mean_absolute_error: 16222.9058 - val_loss: 1094411176.9863 - val_mean_absolute_error: 20256.2855\n",
      "Epoch 206/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 737393444.3288 - mean_absolute_error: 16142.8590 - val_loss: 1092869905.3151 - val_mean_absolute_error: 20463.6876\n",
      "Epoch 207/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 738951591.5068 - mean_absolute_error: 16244.6017 - val_loss: 1102732837.9178 - val_mean_absolute_error: 20309.1534\n",
      "Epoch 208/300\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 738223485.6986 - mean_absolute_error: 16231.8089 - val_loss: 1095634682.0822 - val_mean_absolute_error: 20232.4952\n",
      "Epoch 209/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 736608992.1918 - mean_absolute_error: 16189.4821 - val_loss: 1089178636.0548 - val_mean_absolute_error: 20213.5782\n",
      "Epoch 210/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 88us/step - loss: 733591755.6164 - mean_absolute_error: 16149.6276 - val_loss: 1084483272.7671 - val_mean_absolute_error: 20186.6057\n",
      "Epoch 211/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 733109385.5342 - mean_absolute_error: 16107.4311 - val_loss: 1100530835.0685 - val_mean_absolute_error: 20230.8098\n",
      "Epoch 212/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 730011472.2740 - mean_absolute_error: 16092.7444 - val_loss: 1085334026.3014 - val_mean_absolute_error: 20349.0376\n",
      "Epoch 213/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 729818969.5342 - mean_absolute_error: 16152.0218 - val_loss: 1085337330.8493 - val_mean_absolute_error: 20154.0728\n",
      "Epoch 214/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 727101446.0548 - mean_absolute_error: 16022.6313 - val_loss: 1088565134.4658 - val_mean_absolute_error: 20186.0971\n",
      "Epoch 215/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 728904609.5068 - mean_absolute_error: 16062.2967 - val_loss: 1075498958.2466 - val_mean_absolute_error: 20147.7453\n",
      "Epoch 216/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 727695268.2466 - mean_absolute_error: 16066.1087 - val_loss: 1087525405.3699 - val_mean_absolute_error: 20221.8137\n",
      "Epoch 217/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 723415148.8493 - mean_absolute_error: 16090.8782 - val_loss: 1092707980.4932 - val_mean_absolute_error: 20270.5426\n",
      "Epoch 218/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 725304780.5205 - mean_absolute_error: 16006.0745 - val_loss: 1077264688.8767 - val_mean_absolute_error: 20140.0106\n",
      "Epoch 219/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 721297387.8356 - mean_absolute_error: 16058.5439 - val_loss: 1066895842.1918 - val_mean_absolute_error: 20197.1867\n",
      "Epoch 220/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 719819758.9863 - mean_absolute_error: 16049.1342 - val_loss: 1067683125.4795 - val_mean_absolute_error: 20126.5855\n",
      "Epoch 221/300\n",
      "1168/1168 [==============================] - 0s 83us/step - loss: 717907372.0274 - mean_absolute_error: 16077.8609 - val_loss: 1067395445.2603 - val_mean_absolute_error: 20100.8638\n",
      "Epoch 222/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 715081087.1781 - mean_absolute_error: 15905.1678 - val_loss: 1063995607.2329 - val_mean_absolute_error: 20116.8647\n",
      "Epoch 223/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 714709056.3014 - mean_absolute_error: 15960.2569 - val_loss: 1060255762.6301 - val_mean_absolute_error: 20127.8413\n",
      "Epoch 224/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 708249805.9726 - mean_absolute_error: 15897.9291 - val_loss: 1088765415.8904 - val_mean_absolute_error: 20404.2620\n",
      "Epoch 225/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 716904499.7808 - mean_absolute_error: 15883.6532 - val_loss: 1059958056.7671 - val_mean_absolute_error: 20074.0151\n",
      "Epoch 226/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 711752096.0548 - mean_absolute_error: 15841.3474 - val_loss: 1058571392.4384 - val_mean_absolute_error: 20063.0386\n",
      "Epoch 227/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 712072189.6438 - mean_absolute_error: 15892.6127 - val_loss: 1060617968.8767 - val_mean_absolute_error: 20058.1209\n",
      "Epoch 228/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 712508685.8356 - mean_absolute_error: 15868.2305 - val_loss: 1059822634.7397 - val_mean_absolute_error: 20049.2953\n",
      "Epoch 229/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 707142179.6164 - mean_absolute_error: 15872.2359 - val_loss: 1055654488.3288 - val_mean_absolute_error: 20046.8613\n",
      "Epoch 230/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 708042476.7945 - mean_absolute_error: 15810.6989 - val_loss: 1053540338.8493 - val_mean_absolute_error: 20230.7847\n",
      "Epoch 231/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 709661826.7123 - mean_absolute_error: 15892.5042 - val_loss: 1053040379.6164 - val_mean_absolute_error: 20061.1728\n",
      "Epoch 232/300\n",
      "1168/1168 [==============================] - 0s 91us/step - loss: 703371740.8219 - mean_absolute_error: 15743.5222 - val_loss: 1050019448.7671 - val_mean_absolute_error: 20202.1780\n",
      "Epoch 233/300\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 705542028.4110 - mean_absolute_error: 15974.8874 - val_loss: 1046697845.2603 - val_mean_absolute_error: 20092.0690\n",
      "Epoch 234/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 702360528.7397 - mean_absolute_error: 15795.2841 - val_loss: 1052896225.3151 - val_mean_absolute_error: 20060.5320\n",
      "Epoch 235/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 700691303.6986 - mean_absolute_error: 15823.8835 - val_loss: 1047436286.0274 - val_mean_absolute_error: 20030.7250\n",
      "Epoch 236/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 700610956.4110 - mean_absolute_error: 15760.1888 - val_loss: 1045138873.4247 - val_mean_absolute_error: 20088.2598\n",
      "Epoch 237/300\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 700634818.3288 - mean_absolute_error: 15873.5371 - val_loss: 1050259208.3288 - val_mean_absolute_error: 20037.6739\n",
      "Epoch 238/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 698453390.1918 - mean_absolute_error: 15871.6254 - val_loss: 1052189057.0959 - val_mean_absolute_error: 20042.2266\n",
      "Epoch 239/300\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 696713331.1507 - mean_absolute_error: 15686.5461 - val_loss: 1046048202.9589 - val_mean_absolute_error: 20041.1728\n",
      "Epoch 240/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 693319859.7260 - mean_absolute_error: 15653.8531 - val_loss: 1047085633.9726 - val_mean_absolute_error: 20032.2924\n",
      "Epoch 241/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 693463787.3425 - mean_absolute_error: 15665.8046 - val_loss: 1055609620.1644 - val_mean_absolute_error: 20144.1420\n",
      "Epoch 242/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 694781019.8630 - mean_absolute_error: 15662.8437 - val_loss: 1049967006.2466 - val_mean_absolute_error: 20083.4390\n",
      "Epoch 243/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 692840236.5753 - mean_absolute_error: 15584.9928 - val_loss: 1043082539.3973 - val_mean_absolute_error: 20052.6424\n",
      "Epoch 244/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 692388281.9452 - mean_absolute_error: 15703.7511 - val_loss: 1054258830.6849 - val_mean_absolute_error: 20111.3618\n",
      "Epoch 245/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 692978382.1096 - mean_absolute_error: 15586.3873 - val_loss: 1040188648.9863 - val_mean_absolute_error: 19994.2632\n",
      "Epoch 246/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 689905480.8493 - mean_absolute_error: 15601.0955 - val_loss: 1038069882.9589 - val_mean_absolute_error: 20011.5526\n",
      "Epoch 247/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 692326404.2466 - mean_absolute_error: 15609.3310 - val_loss: 1035276746.9589 - val_mean_absolute_error: 20004.5371\n",
      "Epoch 248/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 687166532.9589 - mean_absolute_error: 15546.1527 - val_loss: 1039489758.4658 - val_mean_absolute_error: 20031.4484\n",
      "Epoch 249/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 688278425.3151 - mean_absolute_error: 15517.0163 - val_loss: 1032929202.8493 - val_mean_absolute_error: 20015.8176\n",
      "Epoch 250/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 685454755.8356 - mean_absolute_error: 15542.7493 - val_loss: 1047557553.3151 - val_mean_absolute_error: 20145.4756\n",
      "Epoch 251/300\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 685802712.9041 - mean_absolute_error: 15629.6219 - val_loss: 1050657888.4384 - val_mean_absolute_error: 20121.7242\n",
      "Epoch 252/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 93us/step - loss: 684796879.9452 - mean_absolute_error: 15512.3825 - val_loss: 1033828469.2603 - val_mean_absolute_error: 20077.6623\n",
      "Epoch 253/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 683149913.5342 - mean_absolute_error: 15581.8494 - val_loss: 1048783716.3836 - val_mean_absolute_error: 20142.8067\n",
      "Epoch 254/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 682617619.6986 - mean_absolute_error: 15530.0065 - val_loss: 1059374713.8630 - val_mean_absolute_error: 20246.6898\n",
      "Epoch 255/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 685805936.6849 - mean_absolute_error: 15519.4137 - val_loss: 1043921675.3973 - val_mean_absolute_error: 20002.0646\n",
      "Epoch 256/300\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 680246870.4658 - mean_absolute_error: 15521.3370 - val_loss: 1031816498.4110 - val_mean_absolute_error: 19939.7195\n",
      "Epoch 257/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 676434096.4932 - mean_absolute_error: 15387.9968 - val_loss: 1074166331.6164 - val_mean_absolute_error: 20491.9533\n",
      "Epoch 258/300\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 681328342.8219 - mean_absolute_error: 15513.5971 - val_loss: 1034569612.2740 - val_mean_absolute_error: 19971.5173\n",
      "Epoch 259/300\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 678279422.3014 - mean_absolute_error: 15445.6796 - val_loss: 1026121685.0411 - val_mean_absolute_error: 20153.6005\n",
      "Epoch 260/300\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 677515738.3014 - mean_absolute_error: 15497.0013 - val_loss: 1024943123.0685 - val_mean_absolute_error: 20204.4968\n",
      "Epoch 261/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 678364680.2740 - mean_absolute_error: 15493.5858 - val_loss: 1024776950.3562 - val_mean_absolute_error: 19968.5422\n",
      "Epoch 262/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 674338096.3836 - mean_absolute_error: 15367.0915 - val_loss: 1021680758.3562 - val_mean_absolute_error: 19968.6468\n",
      "Epoch 263/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 674874281.3699 - mean_absolute_error: 15390.1041 - val_loss: 1020770954.5205 - val_mean_absolute_error: 20188.1753\n",
      "Epoch 264/300\n",
      "1168/1168 [==============================] - 0s 101us/step - loss: 675298935.5342 - mean_absolute_error: 15411.4169 - val_loss: 1019906328.9863 - val_mean_absolute_error: 20014.2333\n",
      "Epoch 265/300\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 671719857.8082 - mean_absolute_error: 15415.3706 - val_loss: 1016364792.1096 - val_mean_absolute_error: 20028.6713\n",
      "Epoch 266/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 671133203.6712 - mean_absolute_error: 15335.6154 - val_loss: 1014951452.7123 - val_mean_absolute_error: 20008.6972\n",
      "Epoch 267/300\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 671927290.8493 - mean_absolute_error: 15368.1073 - val_loss: 1016356782.4658 - val_mean_absolute_error: 20037.8917\n",
      "Epoch 268/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 672377383.9726 - mean_absolute_error: 15381.3014 - val_loss: 1024156637.8082 - val_mean_absolute_error: 20071.9717\n",
      "Epoch 269/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 668499545.0137 - mean_absolute_error: 15372.5657 - val_loss: 1014179153.5342 - val_mean_absolute_error: 20080.6102\n",
      "Epoch 270/300\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 667004856.1096 - mean_absolute_error: 15349.2542 - val_loss: 1014616948.8219 - val_mean_absolute_error: 20007.6349\n",
      "Epoch 271/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 667012230.0548 - mean_absolute_error: 15327.5193 - val_loss: 1022838136.3288 - val_mean_absolute_error: 20060.6319\n",
      "Epoch 272/300\n",
      "1168/1168 [==============================] - 0s 95us/step - loss: 666154010.2192 - mean_absolute_error: 15334.7487 - val_loss: 1011968924.7123 - val_mean_absolute_error: 20013.9243\n",
      "Epoch 273/300\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 664150132.3288 - mean_absolute_error: 15233.2163 - val_loss: 1029057660.7123 - val_mean_absolute_error: 20160.3937\n",
      "Epoch 274/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 663601073.5616 - mean_absolute_error: 15270.2410 - val_loss: 1027409332.1644 - val_mean_absolute_error: 20100.3966\n",
      "Epoch 275/300\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 663620816.6575 - mean_absolute_error: 15300.3004 - val_loss: 1019650861.3699 - val_mean_absolute_error: 20012.7247\n",
      "Epoch 276/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 661040037.6438 - mean_absolute_error: 15249.2506 - val_loss: 1018464997.2603 - val_mean_absolute_error: 19947.5723\n",
      "Epoch 277/300\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 660248593.0411 - mean_absolute_error: 15239.0862 - val_loss: 1011625145.8630 - val_mean_absolute_error: 20134.9903\n",
      "Epoch 278/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 656770516.8767 - mean_absolute_error: 15297.5039 - val_loss: 1014621687.2329 - val_mean_absolute_error: 20215.7021\n",
      "Epoch 279/300\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 659402468.9315 - mean_absolute_error: 15148.6485 - val_loss: 1006974701.1507 - val_mean_absolute_error: 20114.5518\n",
      "Epoch 280/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 659394660.9863 - mean_absolute_error: 15239.8130 - val_loss: 1012821323.8356 - val_mean_absolute_error: 19975.3393\n",
      "Epoch 281/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 659492299.0959 - mean_absolute_error: 15166.2895 - val_loss: 1015684519.8904 - val_mean_absolute_error: 19998.1455\n",
      "Epoch 282/300\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 658929719.7260 - mean_absolute_error: 15219.0089 - val_loss: 1007847557.6986 - val_mean_absolute_error: 19966.4385\n",
      "Epoch 283/300\n",
      "1168/1168 [==============================] - 0s 94us/step - loss: 656886921.0685 - mean_absolute_error: 15174.8962 - val_loss: 1004368508.4932 - val_mean_absolute_error: 20082.2548\n",
      "Epoch 284/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 656175987.3699 - mean_absolute_error: 15170.2901 - val_loss: 1005983043.0685 - val_mean_absolute_error: 20201.2253\n",
      "Epoch 285/300\n",
      "1168/1168 [==============================] - 0s 98us/step - loss: 654385992.4658 - mean_absolute_error: 15236.4173 - val_loss: 1008966236.2740 - val_mean_absolute_error: 20110.4334\n",
      "Epoch 286/300\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 654565174.2740 - mean_absolute_error: 15229.8078 - val_loss: 1029417064.5479 - val_mean_absolute_error: 20342.0418\n",
      "Epoch 287/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 656591378.1644 - mean_absolute_error: 15199.8277 - val_loss: 1001079148.7123 - val_mean_absolute_error: 20038.9039\n",
      "Epoch 288/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 653435903.0959 - mean_absolute_error: 15187.8265 - val_loss: 1004749541.2603 - val_mean_absolute_error: 20037.6087\n",
      "Epoch 289/300\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 651232008.7945 - mean_absolute_error: 15127.7492 - val_loss: 1000465345.0959 - val_mean_absolute_error: 20007.5775\n",
      "Epoch 290/300\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 653517056.2192 - mean_absolute_error: 15132.6462 - val_loss: 1002625225.2055 - val_mean_absolute_error: 19971.8565\n",
      "Epoch 291/300\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 649724527.6438 - mean_absolute_error: 15128.9572 - val_loss: 1006200602.0822 - val_mean_absolute_error: 19955.6594\n",
      "Epoch 292/300\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 651105175.2055 - mean_absolute_error: 15071.5035 - val_loss: 1001730155.3973 - val_mean_absolute_error: 19974.2134\n",
      "Epoch 293/300\n",
      "1168/1168 [==============================] - 0s 97us/step - loss: 645860303.0685 - mean_absolute_error: 15045.5052 - val_loss: 1013714749.8082 - val_mean_absolute_error: 20002.4398\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 100us/step - loss: 648084048.6301 - mean_absolute_error: 15119.5484 - val_loss: 1011731463.4521 - val_mean_absolute_error: 19987.7568\n",
      "Epoch 295/300\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 648452183.3151 - mean_absolute_error: 15146.1593 - val_loss: 1001424143.1233 - val_mean_absolute_error: 19925.2013\n",
      "Epoch 296/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 645748321.9726 - mean_absolute_error: 15151.3880 - val_loss: 1005628355.5068 - val_mean_absolute_error: 19909.1527\n",
      "Epoch 297/300\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 645307010.3562 - mean_absolute_error: 15054.9502 - val_loss: 1006202997.9178 - val_mean_absolute_error: 19971.1895\n",
      "Epoch 298/300\n",
      "1168/1168 [==============================] - 0s 86us/step - loss: 646275549.8904 - mean_absolute_error: 15072.5697 - val_loss: 1006352635.3973 - val_mean_absolute_error: 19945.5911\n",
      "Epoch 299/300\n",
      "1168/1168 [==============================] - 0s 83us/step - loss: 646073576.8767 - mean_absolute_error: 14998.1947 - val_loss: 997826910.9041 - val_mean_absolute_error: 19907.5990\n",
      "Epoch 300/300\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 646922052.2329 - mean_absolute_error: 15043.9716 - val_loss: 995819537.0959 - val_mean_absolute_error: 19901.0643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=num_epochs, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_history = history.history['val_mean_absolute_error']\n",
    "all_mae_histories.append(mae_history)\n",
    "    \n",
    "val_mse, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_history = history.history['val_mean_absolute_error']\n",
    "all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mse, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history, 'r', label='aver_mae')\n",
    "plt.title('MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
